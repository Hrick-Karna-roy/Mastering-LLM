{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class SimpleTransformer:\n",
        "    def __init__(self, embedding_dim):\n",
        "        self.embedding = {}\n",
        "        self.embedding_dim = embedding_dim\n",
        "        # Initialize weights for query, key, value transformations\n",
        "        self.W_q = torch.rand((embedding_dim, embedding_dim))\n",
        "        self.W_k = torch.rand((embedding_dim, embedding_dim))\n",
        "        self.W_v = torch.rand((embedding_dim, embedding_dim))\n",
        "\n",
        "    def add_word(self, word, vector):\n",
        "        \"\"\"\n",
        "        Add a word with its embedding vector to the embedding dictionary.\n",
        "        \"\"\"\n",
        "        if len(vector) != self.embedding_dim:\n",
        "            raise ValueError(\"Embedding vector must have the correct dimension.\")\n",
        "        self.embedding[word] = torch.tensor(vector)\n",
        "\n",
        "    def get_query(self, word):\n",
        "        \"\"\"\n",
        "        Get the query vector for a given word.\n",
        "        \"\"\"\n",
        "        return torch.matmul(self.embedding[word], self.W_q)\n",
        "\n",
        "    def get_keys_and_values(self):\n",
        "        \"\"\"\n",
        "        Get the key and value vectors for all words.\n",
        "        \"\"\"\n",
        "        K = {word: torch.matmul(embedding_vector, self.W_k) for word, embedding_vector in self.embedding.items()}\n",
        "        V = {word: torch.matmul(embedding_vector, self.W_v) for word, embedding_vector in self.embedding.items()}\n",
        "        return K, V\n",
        "\n",
        "    def calculate_attention(self, Q, K):\n",
        "        \"\"\"\n",
        "        Calculate attention scores for a query Q with respect to all keys K.\n",
        "        \"\"\"\n",
        "        scores = {word: torch.dot(Q, K[word]) / torch.sqrt(torch.tensor(float(self.embedding_dim))) for word in K}\n",
        "        weights = F.softmax(torch.tensor(list(scores.values())), dim=-1)\n",
        "        return scores, weights\n",
        "\n",
        "    def get_new_representation(self, word):\n",
        "        \"\"\"\n",
        "        Calculate the new representation of a word using the attention mechanism.\n",
        "        \"\"\"\n",
        "        Q = self.get_query(word)\n",
        "        K, V = self.get_keys_and_values()\n",
        "        _, weights = self.calculate_attention(Q, K)\n",
        "        new_representation = sum(weights[i] * V[word] for i, word in enumerate(K))\n",
        "        return new_representation\n",
        "\n",
        "# Example usage:\n",
        "embedding_dim = 4\n",
        "transformer = SimpleTransformer(embedding_dim)\n",
        "\n",
        "# Add words to the embedding dictionary\n",
        "transformer.add_word(\"the\", [0.2, 0.1, 0.4, 0.5])\n",
        "transformer.add_word(\"cat\", [0.6, 0.1, 0.8, 0.3])\n",
        "transformer.add_word(\"sat\", [0.5, 0.3, 0.7, 0.2])\n",
        "transformer.add_word(\"on\", [0.4, 0.2, 0.5, 0.6])\n",
        "transformer.add_word(\"mat\", [0.3, 0.5, 0.6, 0.4])\n",
        "\n",
        "# Get the new representation for the word \"sat\"\n",
        "new_representation = transformer.get_new_representation(\"sat\")\n",
        "print(\"New representation for 'sat':\", new_representation)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8dRMYKKPygD",
        "outputId": "e80420a3-49dd-44e3-8bc5-b3a42153bfc5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New representation for 'sat': tensor([0.5006, 0.7689, 0.3331, 0.5602])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8CRgt4K7Pb0O",
        "outputId": "d2aa41b6-1ddb-4c36-b93b-f8f7c1bda975"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder output for 'le': tensor([1.3656, 1.6018, 2.0012, 1.5555])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class SimpleTransformer:\n",
        "    def __init__(self, embedding_dim):\n",
        "        self.embedding = {}\n",
        "        self.embedding_dim = embedding_dim\n",
        "        # Initialize weights for query, key, value transformations (encoder)\n",
        "        self.W_q = torch.rand((embedding_dim, embedding_dim))\n",
        "        self.W_k = torch.rand((embedding_dim, embedding_dim))\n",
        "        self.W_v = torch.rand((embedding_dim, embedding_dim))\n",
        "        # Initialize weights for decoder self-attention and encoder-decoder attention\n",
        "        self.W_q_dec = torch.rand((embedding_dim, embedding_dim))\n",
        "        self.W_k_dec = torch.rand((embedding_dim, embedding_dim))\n",
        "        self.W_v_dec = torch.rand((embedding_dim, embedding_dim))\n",
        "        self.W_q_encdec = torch.rand((embedding_dim, embedding_dim))\n",
        "        self.W_k_encdec = torch.rand((embedding_dim, embedding_dim))\n",
        "        self.W_v_encdec = torch.rand((embedding_dim, embedding_dim))\n",
        "\n",
        "    def add_word(self, word, vector):\n",
        "        \"\"\"\n",
        "        Add a word with its embedding vector to the embedding dictionary.\n",
        "        \"\"\"\n",
        "        if len(vector) != self.embedding_dim:\n",
        "            raise ValueError(\"Embedding vector must have the correct dimension.\")\n",
        "        self.embedding[word] = torch.tensor(vector)\n",
        "\n",
        "    def get_query(self, word):\n",
        "        \"\"\"\n",
        "        Get the query vector for a given word (encoder).\n",
        "        \"\"\"\n",
        "        return torch.matmul(self.embedding[word], self.W_q)\n",
        "\n",
        "    def get_keys_and_values(self):\n",
        "        \"\"\"\n",
        "        Get the key and value vectors for all words (encoder).\n",
        "        \"\"\"\n",
        "        K = {word: torch.matmul(embedding_vector, self.W_k) for word, embedding_vector in self.embedding.items()}\n",
        "        V = {word: torch.matmul(embedding_vector, self.W_v) for word, embedding_vector in self.embedding.items()}\n",
        "        return K, V\n",
        "\n",
        "    def calculate_attention(self, Q, K):\n",
        "        \"\"\"\n",
        "        Calculate attention scores for a query Q with respect to all keys K.\n",
        "        \"\"\"\n",
        "        scores = {word: torch.dot(Q, K[word]) / torch.sqrt(torch.tensor(float(self.embedding_dim))) for word in K}\n",
        "        weights = F.softmax(torch.tensor(list(scores.values())), dim=-1)\n",
        "        return scores, weights\n",
        "\n",
        "    def get_new_representation(self, word):\n",
        "        \"\"\"\n",
        "        Calculate the new representation of a word using the attention mechanism (encoder).\n",
        "        \"\"\"\n",
        "        Q = self.get_query(word)\n",
        "        K, V = self.get_keys_and_values()\n",
        "        _, weights = self.calculate_attention(Q, K)\n",
        "        new_representation = sum(weights[i] * V[word] for i, word in enumerate(K))\n",
        "        return new_representation\n",
        "\n",
        "    def decoder_attention(self, word, encoder_outputs):\n",
        "        \"\"\"\n",
        "        Perform self-attention for the decoder and encoder-decoder attention.\n",
        "        \"\"\"\n",
        "        Q_dec = torch.matmul(self.embedding[word], self.W_q_dec)\n",
        "        K_dec = {w: torch.matmul(enc_out, self.W_k_dec) for w, enc_out in encoder_outputs.items()}\n",
        "        V_dec = {w: torch.matmul(enc_out, self.W_v_dec) for w, enc_out in encoder_outputs.items()}\n",
        "        _, weights_dec = self.calculate_attention(Q_dec, K_dec)\n",
        "        dec_self_attention = sum(weights_dec[i] * V_dec[w] for i, w in enumerate(K_dec))\n",
        "\n",
        "        # Encoder-Decoder Attention\n",
        "        Q_encdec = torch.matmul(dec_self_attention, self.W_q_encdec)\n",
        "        K_encdec = {w: torch.matmul(enc_out, self.W_k_encdec) for w, enc_out in encoder_outputs.items()}\n",
        "        V_encdec = {w: torch.matmul(enc_out, self.W_v_encdec) for w, enc_out in encoder_outputs.items()}\n",
        "        _, weights_encdec = self.calculate_attention(Q_encdec, K_encdec)\n",
        "        new_representation = sum(weights_encdec[i] * V_encdec[w] for i, w in enumerate(K_encdec))\n",
        "\n",
        "        return new_representation\n",
        "\n",
        "# Example usage:\n",
        "embedding_dim = 4\n",
        "transformer = SimpleTransformer(embedding_dim)\n",
        "\n",
        "# Add words to the embedding dictionary (English to French example)\n",
        "transformer.add_word(\"the\", [0.2, 0.1, 0.4, 0.5])\n",
        "transformer.add_word(\"cat\", [0.6, 0.1, 0.8, 0.3])\n",
        "transformer.add_word(\"sat\", [0.5, 0.3, 0.7, 0.2])\n",
        "transformer.add_word(\"on\", [0.4, 0.2, 0.5, 0.6])\n",
        "transformer.add_word(\"mat\", [0.3, 0.5, 0.6, 0.4])\n",
        "transformer.add_word(\"le\", [0.1, 0.2, 0.4, 0.6])\n",
        "transformer.add_word(\"chat\", [0.5, 0.6, 0.3, 0.2])\n",
        "transformer.add_word(\"assis\", [0.7, 0.4, 0.1, 0.5])\n",
        "transformer.add_word(\"sur\", [0.3, 0.7, 0.2, 0.4])\n",
        "transformer.add_word(\"tapis\", [0.4, 0.6, 0.3, 0.5])\n",
        "\n",
        "# Step 1: Encoder processes the input sentence\n",
        "encoder_outputs = {word: transformer.get_new_representation(word) for word in [\"the\", \"cat\", \"sat\", \"on\", \"mat\"]}\n",
        "\n",
        "# Step 2: Decoder processes the target sentence (with encoder outputs)\n",
        "decoded_representation = transformer.decoder_attention(\"le\", encoder_outputs)\n",
        "print(\"Decoder output for 'le':\", decoded_representation)\n"
      ]
    }
  ]
}